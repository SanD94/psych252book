[
["linear-model-3.html", "Chapter 12 Linear model 3 12.1 Learning goals 12.2 Load packages and set plotting theme 12.3 Load data sets 12.4 One-way ANOVA 12.5 Two-way ANOVA 12.6 Additional resources 12.7 Session info", " Chapter 12 Linear model 3 12.1 Learning goals Linear model with one multi-level categorical predictor (One-way ANOVA). Linear model with multiple categorical predictors (N-way ANOVA). dummy-coding vs. effect-coding planned contrasts 12.2 Load packages and set plotting theme library(&quot;knitr&quot;) # for knitting RMarkdown library(&quot;kableExtra&quot;) # for making nice tables library(&quot;janitor&quot;) # for cleaning column names library(&quot;broom&quot;) # for tidying up linear models library(&quot;car&quot;) # for running ANOVAs library(&quot;afex&quot;) # also for running ANOVAs library(&quot;emmeans&quot;) # for calculating constrasts library(&quot;tidyverse&quot;) # for wrangling, plotting, etc. theme_set(theme_classic() + #set the theme theme(text = element_text(size = 20))) #set the default text size 12.3 Load data sets df.poker = read_csv(&quot;data/poker.csv&quot;) %&gt;% mutate(skill = factor(skill, levels = 1:2, labels = c(&quot;expert&quot;, &quot;average&quot;)), skill = fct_relevel(skill, &quot;average&quot;, &quot;expert&quot;), hand = factor(hand, levels = 1:3, labels = c(&quot;bad&quot;, &quot;neutral&quot;, &quot;good&quot;)), limit = factor(limit, levels = 1:2, labels = c(&quot;fixed&quot;, &quot;none&quot;)), participant = 1:n()) %&gt;% select(participant, everything()) Selection of the data: df.poker %&gt;% group_by(skill, hand, limit) %&gt;% filter(row_number() &lt; 3) %&gt;% head(10) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F) participant skill hand limit balance 1 expert bad fixed 4.00 2 expert bad fixed 5.55 26 expert bad none 5.52 27 expert bad none 8.28 51 expert neutral fixed 11.74 52 expert neutral fixed 10.04 76 expert neutral none 21.55 77 expert neutral none 3.12 101 expert good fixed 10.86 102 expert good fixed 8.68 12.4 One-way ANOVA 12.4.1 Visualization df.poker %&gt;% ggplot(mapping = aes(x = hand, y = balance, fill = hand)) + geom_point(alpha = 0.2, position = position_jitter(height = 0, width = 0.1)) + stat_summary(fun.data = &quot;mean_cl_boot&quot;, geom = &quot;linerange&quot;, size = 1) + stat_summary(fun.y = &quot;mean&quot;, geom = &quot;point&quot;, shape = 21, size = 4) + labs(y = &quot;final balance (in Euros)&quot;) + scale_fill_manual(values = c(&quot;red&quot;, &quot;orange&quot;, &quot;green&quot;)) + theme(legend.position = &quot;none&quot;) 12.4.2 Model fitting We pass the result of the lm() function to anova() to calculate an analysis of variance like so: lm(formula = balance ~ hand, data = df.poker) %&gt;% anova() ## Analysis of Variance Table ## ## Response: balance ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## hand 2 2559.4 1279.7 75.703 &lt; 2.2e-16 *** ## Residuals 297 5020.6 16.9 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 12.4.3 Hypothesis test The F-test reported by the ANOVA compares the fitted model with a compact model that only predicts the grand mean: # fit the models fit_c = lm(formula = balance ~ 1, data = df.poker) fit_a = lm(formula = balance ~ hand, data = df.poker) # compare via F-test anova(fit_c, fit_a) ## Analysis of Variance Table ## ## Model 1: balance ~ 1 ## Model 2: balance ~ hand ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 299 7580.0 ## 2 297 5020.6 2 2559.4 75.703 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 12.4.4 Visualize the model’s predictions Here is the model prediction of the compact model: set.seed(1) df.plot = df.poker %&gt;% mutate(hand_jitter = 1 + runif(n(), min = -0.25, max = 0.25)) df.augment = fit_c %&gt;% augment() %&gt;% clean_names() %&gt;% bind_cols(df.plot %&gt;% select(balance, hand, hand_jitter)) ggplot(data = df.plot, mapping = aes(x = hand_jitter, y = balance, fill = hand)) + geom_hline(yintercept = mean(df.poker$balance)) + geom_point(alpha = 0.5) + geom_segment(data = df.augment, aes(xend = hand_jitter, yend = fitted), alpha = 0.2) + labs(y = &quot;balance&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_blank(), axis.title.x = element_blank()) Note that since we have a categorical variable here, we don’t really have a continuous x-axis. I’ve just jittered the values so it’s easier to show the residuals. And here is the prediction of the augmented model (which predicts different means for each group). set.seed(1) df.plot = df.poker %&gt;% mutate(hand_jitter = hand %&gt;% as.numeric(), hand_jitter = hand_jitter + runif(n(), min = -0.4, max = 0.4)) df.tidy = fit_a %&gt;% tidy() %&gt;% select_if(is.numeric) %&gt;% mutate_all(~ round(., digits = 2)) df.augment = fit_a %&gt;% augment() %&gt;% clean_names() %&gt;% bind_cols(df.plot %&gt;% select(hand_jitter)) ggplot(data = df.plot, mapping = aes(x = hand_jitter, y = balance, color = hand)) + geom_point(alpha = 0.8) + geom_segment(data = NULL, aes(x = 0.6, xend = 1.4, y = df.tidy$estimate[1], yend = df.tidy$estimate[1] ), color = &quot;red&quot;, size = 1) + geom_segment(data = NULL, aes(x = 1.6, xend = 2.4, y = df.tidy$estimate[1] + df.tidy$estimate[2], yend = df.tidy$estimate[1] + df.tidy$estimate[2] ), color = &quot;orange&quot;, size = 1) + geom_segment(data = NULL, aes(x = 2.6, xend = 3.4, y = df.tidy$estimate[1] + df.tidy$estimate[3], yend = df.tidy$estimate[1] + df.tidy$estimate[3] ), color = &quot;green&quot;, size = 1) + geom_segment(data = df.augment, aes(xend = hand_jitter, y = balance, yend = fitted), alpha = 0.3) + labs(y = &quot;balance&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;orange&quot;, &quot;green&quot;)) + scale_x_continuous(breaks = 1:3, labels = c(&quot;bad&quot;, &quot;neutral&quot;, &quot;good&quot;)) + theme(legend.position = &quot;none&quot;, axis.title.x = element_blank()) The vertical lines illustrate the residual sum of squares. We can illustrate the model sum of squares like so: set.seed(1) df.plot = df.poker %&gt;% mutate(hand_jitter = hand %&gt;% as.numeric(), hand_jitter = hand_jitter + runif(n(), min = -0.4, max = 0.4)) %&gt;% group_by(hand) %&gt;% mutate(mean_group = mean(balance)) %&gt;% ungroup() %&gt;% mutate(mean_grand = mean(balance)) df.means = df.poker %&gt;% group_by(hand) %&gt;% summarize(mean = mean(balance)) %&gt;% pivot_wider(names_from = hand, values_from = mean) ggplot(data = df.plot, mapping = aes(x = hand_jitter, y = mean_group, color = hand)) + geom_point(alpha = 0.8) + geom_segment(data = NULL, mapping = aes(x = 0.6, xend = 1.4, y = df.means$bad, yend = df.means$bad), color = &quot;red&quot;, size = 1) + geom_segment(data = NULL, mapping = aes(x = 1.6, xend = 2.4, y = df.means$neutral, yend = df.means$neutral), color = &quot;orange&quot;, size = 1) + geom_segment(data = NULL, mapping = aes(x = 2.6, xend = 3.4, y = df.means$good, yend = df.means$good), color = &quot;green&quot;, size = 1) + geom_segment(mapping = aes(xend = hand_jitter, y = mean_group, yend = mean_grand), alpha = 0.3) + geom_hline(yintercept = mean(df.poker$balance), size = 1) + labs(y = &quot;balance&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;orange&quot;, &quot;green&quot;)) + scale_x_continuous(breaks = 1:3, labels = c(&quot;bad&quot;, &quot;neutral&quot;, &quot;good&quot;)) + scale_y_continuous(breaks = c(0, 10, 20), labels = c(0, 10, 20), limits = c(0, 25)) + theme(legend.position = &quot;none&quot;, axis.title.x = element_blank()) This captures the variance in the data that is accounted for by the hand variable. Just for kicks, let’s calculate our cherished proportion of reduction in error PRE: df.c = fit_c %&gt;% augment() %&gt;% clean_names() %&gt;% summarize(sse = sum(resid^2) %&gt;% round) df.a = fit_a %&gt;% augment() %&gt;% clean_names() %&gt;% summarize(sse = sum(resid^2) %&gt;% round) pre = 1 - df.a$sse/df.c$sse print(pre %&gt;% round(2)) ## [1] 0.34 Note that this is the same as the \\(R^2\\) for the augmented model: fit_a %&gt;% summary() ## ## Call: ## lm(formula = balance ~ hand, data = df.poker) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.9264 -2.5902 -0.0115 2.6573 15.2834 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.9415 0.4111 14.451 &lt; 2e-16 *** ## handneutral 4.4051 0.5815 7.576 4.55e-13 *** ## handgood 7.0849 0.5815 12.185 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.111 on 297 degrees of freedom ## Multiple R-squared: 0.3377, Adjusted R-squared: 0.3332 ## F-statistic: 75.7 on 2 and 297 DF, p-value: &lt; 2.2e-16 12.4.5 Dummy coding Let’s check that we understand how dummy-coding works for a variable with more than 2 levels: # dummy code the hand variable df.poker = df.poker %&gt;% mutate(hand_neutral = ifelse(hand == &quot;neutral&quot;, 1, 0), hand_good = ifelse(hand == &quot;good&quot;, 1, 0)) # show the dummy coded variables df.poker %&gt;% select(participant, contains(&quot;hand&quot;), balance) %&gt;% group_by(hand) %&gt;% top_n(3) %&gt;% head(10) %&gt;% kable(digits = 3) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F) ## Selecting by balance participant hand hand_neutral hand_good balance 31 bad 0 0 12.22 46 bad 0 0 12.06 50 bad 0 0 16.68 76 neutral 1 0 21.55 87 neutral 1 0 20.89 89 neutral 1 0 25.63 127 good 0 1 26.99 129 good 0 1 21.36 283 good 0 1 22.48 # fit the model fit.tmp = lm(balance ~ 1 + hand_neutral + hand_good, df.poker) # show the model summary fit.tmp %&gt;% summary() ## ## Call: ## lm(formula = balance ~ 1 + hand_neutral + hand_good, data = df.poker) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.9264 -2.5902 -0.0115 2.6573 15.2834 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.9415 0.4111 14.451 &lt; 2e-16 *** ## hand_neutral 4.4051 0.5815 7.576 4.55e-13 *** ## hand_good 7.0849 0.5815 12.185 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.111 on 297 degrees of freedom ## Multiple R-squared: 0.3377, Adjusted R-squared: 0.3332 ## F-statistic: 75.7 on 2 and 297 DF, p-value: &lt; 2.2e-16 Here, I’ve directly put the dummy-coded variables as predictors into the lm(). We get the same model as if we used the hand variable instead. 12.4.6 Follow up questions Here are some follow up questions we may ask about the data. Are bad hands different from neutral hands? df.poker %&gt;% filter(hand %in% c(&quot;bad&quot;, &quot;neutral&quot;)) %&gt;% lm(formula = balance ~ hand, data = .) %&gt;% summary() ## ## Call: ## lm(formula = balance ~ hand, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.9566 -2.5078 -0.2365 2.4410 15.2834 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.9415 0.3816 15.570 &lt; 2e-16 *** ## handneutral 4.4051 0.5397 8.163 3.76e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.816 on 198 degrees of freedom ## Multiple R-squared: 0.2518, Adjusted R-squared: 0.248 ## F-statistic: 66.63 on 1 and 198 DF, p-value: 3.758e-14 Are neutral hands different from good hands? df.poker %&gt;% filter(hand %in% c(&quot;neutral&quot;, &quot;good&quot;)) %&gt;% lm(formula = balance ~ hand, data = .) %&gt;% summary() ## ## Call: ## lm(formula = balance ~ hand, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.9264 -2.7141 0.2585 2.7184 15.2834 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.3466 0.4448 23.26 &lt; 2e-16 *** ## handgood 2.6798 0.6291 4.26 3.16e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.448 on 198 degrees of freedom ## Multiple R-squared: 0.08396, Adjusted R-squared: 0.07933 ## F-statistic: 18.15 on 1 and 198 DF, p-value: 3.158e-05 Doing the same thing by recoding our hand factor and taking “neutral” to be the reference category: df.poker %&gt;% mutate(hand = fct_relevel(hand, &quot;neutral&quot;)) %&gt;% lm(formula = balance ~ hand, data = .) %&gt;% summary() ## ## Call: ## lm(formula = balance ~ hand, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.9264 -2.5902 -0.0115 2.6573 15.2834 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.3466 0.4111 25.165 &lt; 2e-16 *** ## handbad -4.4051 0.5815 -7.576 4.55e-13 *** ## handgood 2.6798 0.5815 4.609 6.02e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.111 on 297 degrees of freedom ## Multiple R-squared: 0.3377, Adjusted R-squared: 0.3332 ## F-statistic: 75.7 on 2 and 297 DF, p-value: &lt; 2.2e-16 12.4.7 Variance decomposition Let’s first run the model fit = lm(formula = balance ~ hand, data = df.poker) fit %&gt;% anova() ## Analysis of Variance Table ## ## Response: balance ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## hand 2 2559.4 1279.7 75.703 &lt; 2.2e-16 *** ## Residuals 297 5020.6 16.9 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 12.4.7.1 Calculate sums of squares And then let’s make sure that we understand how the variance is broken down: df.poker %&gt;% mutate(mean_grand = mean(balance)) %&gt;% group_by(hand) %&gt;% mutate(mean_group = mean(balance)) %&gt;% ungroup() %&gt;% summarize(variance_total = sum((balance - mean_grand)^2), variance_model = sum((mean_group - mean_grand)^2), variance_residual = variance_total - variance_model) ## # A tibble: 1 x 3 ## variance_total variance_model variance_residual ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7580. 2559. 5021. 12.4.7.2 Visualize model predictions 12.4.7.2.1 Total variance set.seed(1) fit_c = lm(formula = balance ~ 1, data = df.poker) df.plot = df.poker %&gt;% mutate(hand_jitter = 1 + runif(n(), min = -0.25, max = 0.25)) df.augment = fit_c %&gt;% augment() %&gt;% clean_names() %&gt;% bind_cols(df.plot %&gt;% select(balance, hand, hand_jitter)) ggplot(data = df.plot, mapping = aes(x = hand_jitter, y = balance, fill = hand)) + geom_hline(yintercept = mean(df.poker$balance)) + geom_point(alpha = 0.5) + geom_segment(data = df.augment, aes(xend = hand_jitter, yend = fitted), alpha = 0.2) + labs(y = &quot;balance&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_blank(), axis.title.x = element_blank()) 12.4.7.2.2 Model variance set.seed(1) df.plot = df.poker %&gt;% mutate(hand_jitter = hand %&gt;% as.numeric(), hand_jitter = hand_jitter + runif(n(), min = -0.4, max = 0.4)) %&gt;% group_by(hand) %&gt;% mutate(mean_group = mean(balance)) %&gt;% ungroup() %&gt;% mutate(mean_grand = mean(balance)) df.means = df.poker %&gt;% group_by(hand) %&gt;% summarize(mean = mean(balance)) %&gt;% pivot_wider(names_from = hand, values_from = mean) ggplot(data = df.plot, mapping = aes(x = hand_jitter, y = mean_group, color = hand)) + geom_point(alpha = 0.8) + geom_segment(data = NULL, aes(x = 0.6, xend = 1.4, y = df.means$bad, yend = df.means$bad), color = &quot;red&quot;, size = 1) + geom_segment(data = NULL, aes(x = 1.6, xend = 2.4, y = df.means$neutral, yend = df.means$neutral), color = &quot;orange&quot;, size = 1) + geom_segment(data = NULL, aes(x = 2.6, xend = 3.4, y = df.means$good, yend = df.means$good), color = &quot;green&quot;, size = 1) + geom_segment(aes(xend = hand_jitter, y = mean_group, yend = mean_grand), alpha = 0.3) + geom_hline(yintercept = mean(df.poker$balance), size = 1) + labs(y = &quot;balance&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;orange&quot;, &quot;green&quot;)) + scale_x_continuous(breaks = 1:3, labels = c(&quot;bad&quot;, &quot;neutral&quot;, &quot;good&quot;)) + scale_y_continuous(breaks = c(0, 10, 20), labels = c(0, 10, 20), limits = c(0, 25)) + theme(legend.position = &quot;none&quot;, axis.title.x = element_blank()) 12.4.7.2.3 Residual variance set.seed(1) fit_a = lm(formula = balance ~ hand, data = df.poker) df.plot = df.poker %&gt;% mutate(hand_jitter = hand %&gt;% as.numeric(), hand_jitter = hand_jitter + runif(n(), min = -0.4, max = 0.4)) df.tidy = fit_a %&gt;% tidy() %&gt;% select_if(is.numeric) %&gt;% mutate_all(~ round(., digits = 2)) df.augment = fit_a %&gt;% augment() %&gt;% clean_names() %&gt;% bind_cols(df.plot %&gt;% select(hand_jitter)) ggplot(data = df.plot, mapping = aes(x = hand_jitter, y = balance, color = hand)) + geom_point(alpha = 0.8) + geom_segment(data = NULL, aes(x = 0.6, xend = 1.4, y = df.tidy$estimate[1], yend = df.tidy$estimate[1]), color = &quot;red&quot;, size = 1) + geom_segment(data = NULL, aes(x = 1.6, xend = 2.4, y = df.tidy$estimate[1] + df.tidy$estimate[2], yend = df.tidy$estimate[1] + df.tidy$estimate[2]), color = &quot;orange&quot;, size = 1) + geom_segment(data = NULL, aes(x = 2.6, xend = 3.4, y = df.tidy$estimate[1] + df.tidy$estimate[3], yend = df.tidy$estimate[1] + df.tidy$estimate[3]), color = &quot;green&quot;, size = 1) + geom_segment(data = df.augment, aes(xend = hand_jitter, y = balance, yend = fitted), alpha = 0.3) + labs(y = &quot;balance&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;orange&quot;, &quot;green&quot;)) + scale_x_continuous(breaks = 1:3, labels = c(&quot;bad&quot;, &quot;neutral&quot;, &quot;good&quot;)) + theme(legend.position = &quot;none&quot;, axis.title.x = element_blank()) 12.5 Two-way ANOVA Now let’s take a look at a case where we have multiple categorical predictors. 12.5.1 Visualization Let’s look at the overall effect of skill: ggplot(data = df.poker, mapping = aes(x = skill, y = balance)) + geom_point(position = position_jitter(width = 0.2, height = 0), alpha = 0.2) + stat_summary(fun.data = &quot;mean_cl_boot&quot;, geom = &quot;linerange&quot;, color = &quot;black&quot;, position = position_dodge(0.9)) + stat_summary(fun.y = &quot;mean&quot;, geom = &quot;point&quot;, color = &quot;black&quot;, position = position_dodge(0.9), aes(shape = skill), size = 3, fill = &quot;black&quot;) + scale_shape_manual(values = c(21, 22)) + guides(shape = F) And now let’s take a look at the means for the full the 3 (hand) x 2 (skill) design: ggplot(data = df.poker, mapping = aes(x = hand, y = balance, group = skill, fill = hand)) + geom_point(position = position_jitterdodge(jitter.width = 0.3, jitter.height = 0, dodge.width = 0.9), alpha = 0.2) + stat_summary(fun.data = &quot;mean_cl_boot&quot;, geom = &quot;linerange&quot;, color = &quot;black&quot;, position = position_dodge(0.9)) + stat_summary(fun.y = &quot;mean&quot;, geom = &quot;point&quot;, aes(shape = skill), color = &quot;black&quot;, position = position_dodge(0.9), size = 3) + scale_fill_manual(values = c(&quot;red&quot;, &quot;orange&quot;, &quot;green&quot;)) + scale_shape_manual(values = c(21, 22)) + guides(fill = F) 12.5.2 Model fitting For N-way ANOVAs, we need to be careful about what sums of squares we are using. The standard (based on the SPSS output) is to use type III sums of squares. We set this up in the following way: lm(formula = balance ~ hand * skill, data = df.poker, contrasts = list(hand = &quot;contr.sum&quot;, skill = &quot;contr.sum&quot;)) %&gt;% Anova(type = 3) ## Anova Table (Type III tests) ## ## Response: balance ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 28644.7 1 1772.1137 &lt; 2.2e-16 *** ## hand 2559.4 2 79.1692 &lt; 2.2e-16 *** ## skill 39.3 1 2.4344 0.1197776 ## hand:skill 229.0 2 7.0830 0.0009901 *** ## Residuals 4752.3 294 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 So, we fit our linear model, but set the contrasts to “contr.sum” (which yields effect coding instead of dummy coding), and then specify the desired type of sums of squares in the Anova() function call. Alternatively, we could use the afex package and specify the ANOVA like so: aov_ez(id = &quot;participant&quot;, dv = &quot;balance&quot;, data = df.poker, between = c(&quot;hand&quot;, &quot;skill&quot;) ) ## Contrasts set to contr.sum for the following variables: hand, skill ## Anova Table (Type 3 tests) ## ## Response: balance ## Effect df MSE F ges p.value ## 1 hand 2, 294 16.16 79.17 *** .35 &lt;.0001 ## 2 skill 1, 294 16.16 2.43 .008 .12 ## 3 hand:skill 2, 294 16.16 7.08 *** .05 .0010 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 The afex package uses effect coding and type 3 sums of squares by default. 12.5.3 Interpreting interactions Code I’ve used to generate the different plots in the competition: set.seed(1) b0 = 15 nsamples = 30 sd = 5 # simple effect of condition b1 = 10 b2 = 1 b1_2 = 1 # two simple effects # b1 = 5 # b2 = -5 # b1_2 = 0 # interaction effect # b1 = 10 # b2 = 10 # b1_2 = -20 # interaction and simple effect # b1 = 10 # b2 = 0 # b1_2 = -20 # all three # b1 = 2 # b2 = 2 # b1_2 = 10 df.data = tibble( condition = rep(c(0, 1), each = nsamples), treatment = rep(c(0, 1), nsamples), rating = b0 + b1 * condition + b2 * treatment + (b1_2 * condition * treatment) + rnorm(nsamples, sd = sd)) %&gt;% mutate(condition = factor(condition, labels = c(&quot;A&quot;, &quot;B&quot;)), treatment = factor(treatment, labels = c(&quot;1&quot;, &quot;2&quot;))) ggplot(df.data, aes(x = condition, y = rating, group = treatment, fill = treatment)) + stat_summary(fun.y = &quot;mean&quot;, geom = &quot;bar&quot;, color = &quot;black&quot;, position = position_dodge(0.9)) + stat_summary(fun.data = &quot;mean_cl_boot&quot;, geom = &quot;linerange&quot;, size = 1, position = position_dodge(0.9)) + scale_fill_brewer(palette = &quot;Set1&quot;) And here is one specific example. Let’s generate the data first: # make example reproducible set.seed(1) # set parameters nsamples = 30 b0 = 15 b1 = 10 # simple effect of condition b2 = 0 # simple effect of treatment b1_2 = -20 # interaction effect sd = 5 # generate data df.data = tibble( condition = rep(c(0, 1), each = nsamples), treatment = rep(c(0, 1), nsamples), rating = b0 + b1 * condition + b2 * treatment + (b1_2 * condition * treatment) + rnorm(nsamples, sd = sd)) %&gt;% mutate(condition = factor(condition, labels = c(&quot;A&quot;, &quot;B&quot;)), treatment = factor(treatment, labels = c(&quot;1&quot;, &quot;2&quot;))) Show part of the generated data frame: # show data frame df.data %&gt;% group_by(condition, treatment) %&gt;% filter(row_number() &lt; 3) %&gt;% ungroup() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F) condition treatment rating A 1 11.87 A 2 15.92 A 1 10.82 A 2 22.98 B 1 21.87 B 2 5.92 B 1 20.82 B 2 12.98 Plot the data: # plot data ggplot(df.data, aes(x = condition, y = rating, group = treatment, fill = treatment)) + stat_summary(fun.y = &quot;mean&quot;, geom = &quot;bar&quot;, color = &quot;black&quot;, position = position_dodge(0.9)) + stat_summary(fun.data = &quot;mean_cl_boot&quot;, geom = &quot;linerange&quot;, size = 1, position = position_dodge(0.9)) + scale_fill_brewer(palette = &quot;Set1&quot;) And check whether we can successfully infer the parameters that we used to generate the data: # infer parameters lm(formula = rating ~ 1 + condition + treatment + condition:treatment, data = df.data) %&gt;% summary() ## ## Call: ## lm(formula = rating ~ 1 + condition + treatment + condition:treatment, ## data = df.data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.6546 -3.6343 0.7988 3.3514 8.3953 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 16.244 1.194 13.608 &lt; 2e-16 *** ## conditionB 10.000 1.688 5.924 2.02e-07 *** ## treatment2 -1.662 1.688 -0.985 0.329 ## conditionB:treatment2 -20.000 2.387 -8.378 1.86e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.623 on 56 degrees of freedom ## Multiple R-squared: 0.7473, Adjusted R-squared: 0.7338 ## F-statistic: 55.21 on 3 and 56 DF, p-value: &lt; 2.2e-16 12.5.4 Variance decomposition Let’s fit the model first: fit = lm(formula = balance ~ hand + skill, data = df.poker) fit %&gt;% anova() ## Analysis of Variance Table ## ## Response: balance ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## hand 2 2559.4 1279.70 76.0437 &lt;2e-16 *** ## skill 1 39.3 39.35 2.3383 0.1273 ## Residuals 296 4981.2 16.83 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 12.5.4.1 Calculate sums of squares df.poker %&gt;% mutate(mean_grand = mean(balance)) %&gt;% group_by(skill) %&gt;% mutate(mean_skill = mean(balance)) %&gt;% group_by(hand) %&gt;% mutate(mean_hand = mean(balance)) %&gt;% ungroup() %&gt;% summarize(variance_total = sum((balance - mean_grand)^2), variance_skill = sum((mean_skill - mean_grand)^2), variance_hand = sum((mean_hand - mean_grand)^2), variance_residual = variance_total - variance_skill - variance_hand) ## # A tibble: 1 x 4 ## variance_total variance_skill variance_hand variance_residual ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7580. 39.3 2559. 4981. 12.5.4.2 Visualize model predictions 12.5.4.2.1 Skill factor set.seed(1) df.plot = df.poker %&gt;% mutate(skill_jitter = skill %&gt;% as.numeric(), skill_jitter = skill_jitter + runif(n(), min = -0.4, max = 0.4)) %&gt;% group_by(skill) %&gt;% mutate(mean_group = mean(balance)) %&gt;% ungroup() %&gt;% mutate(mean_grand = mean(balance)) df.means = df.poker %&gt;% group_by(skill) %&gt;% summarize(mean = mean(balance)) %&gt;% pivot_wider(names_from = skill, values_from = mean) ggplot(data = df.plot, mapping = aes(x = skill_jitter, y = mean_group, color = skill)) + geom_point(alpha = 0.8) + geom_segment(data = NULL, aes(x = 0.6, xend = 1.4, y = df.means$average, yend = df.means$average), color = &quot;black&quot;, size = 1) + geom_segment(data = NULL, aes(x = 1.6, xend = 2.4, y = df.means$expert, yend = df.means$expert), color = &quot;gray50&quot;, size = 1) + geom_segment(aes(xend = skill_jitter, y = mean_group, yend = mean_grand), alpha = 0.3) + geom_hline(yintercept = mean(df.poker$balance), size = 1) + labs(y = &quot;balance&quot;) + scale_color_manual(values = c(&quot;black&quot;, &quot;gray50&quot;)) + scale_x_continuous(breaks = 1:2, labels = c(&quot;average&quot;, &quot;expert&quot;)) + scale_y_continuous(breaks = c(0, 10, 20), labels = c(0, 10, 20), limits = c(0, 25)) + theme(legend.position = &quot;none&quot;, axis.title.x = element_blank()) 12.6 Additional resources 12.6.1 Datacamp Statistical modeling 1 Statistical modeling 2 Correlation and regression 12.6.2 Misc Explanation of different types of sums of squares 12.7 Session info Information about this R session including which version of R was used, and what packages were loaded. sessionInfo() ## R version 3.6.2 (2019-12-12) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS Mojave 10.14.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 purrr_0.3.3 ## [5] readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 ## [9] tidyverse_1.3.0 emmeans_1.4.3.01 afex_0.25-1 lme4_1.1-21 ## [13] Matrix_1.2-18 car_3.0-6 carData_3.0-3 broom_0.5.3 ## [17] janitor_1.2.0 kableExtra_1.1.0 knitr_1.26 ## ## loaded via a namespace (and not attached): ## [1] TH.data_1.0-10 minqa_1.2.4 colorspace_1.4-1 ## [4] rio_0.5.16 snakecase_0.11.0 htmlTable_1.13.3 ## [7] estimability_1.3 base64enc_0.1-3 fs_1.3.1 ## [10] rstudioapi_0.10 farver_2.0.1 fansi_0.4.0 ## [13] mvtnorm_1.0-11 lubridate_1.7.4 xml2_1.2.2 ## [16] codetools_0.2-16 splines_3.6.2 zeallot_0.1.0 ## [19] Formula_1.2-3 jsonlite_1.6 nloptr_1.2.1 ## [22] cluster_2.1.0 dbplyr_1.4.2 png_0.1-7 ## [25] compiler_3.6.2 httr_1.4.1 backports_1.1.5 ## [28] assertthat_0.2.1 lazyeval_0.2.2 cli_2.0.0 ## [31] acepack_1.4.1 htmltools_0.4.0 tools_3.6.2 ## [34] lmerTest_3.1-1 coda_0.19-3 gtable_0.3.0 ## [37] glue_1.3.1 reshape2_1.4.3 Rcpp_1.0.3 ## [40] cellranger_1.1.0 vctrs_0.2.1 nlme_3.1-142 ## [43] xfun_0.11 openxlsx_4.1.4 rvest_0.3.5 ## [46] lifecycle_0.1.0 MASS_7.3-51.4 zoo_1.8-6 ## [49] scales_1.1.0 hms_0.5.2 parallel_3.6.2 ## [52] sandwich_2.5-1 RColorBrewer_1.1-2 yaml_2.2.0 ## [55] curl_4.3 gridExtra_2.3 rpart_4.1-15 ## [58] latticeExtra_0.6-29 stringi_1.4.3 highr_0.8 ## [61] checkmate_1.9.4 boot_1.3-23 zip_2.0.4 ## [64] rlang_0.4.2 pkgconfig_2.0.3 evaluate_0.14 ## [67] lattice_0.20-38 labeling_0.3 htmlwidgets_1.5.1 ## [70] tidyselect_0.2.5 plyr_1.8.5 magrittr_1.5 ## [73] bookdown_0.16 R6_2.4.1 generics_0.0.2 ## [76] Hmisc_4.3-0 multcomp_1.4-11 DBI_1.1.0 ## [79] pillar_1.4.3 haven_2.2.0 foreign_0.8-72 ## [82] withr_2.1.2 nnet_7.3-12 survival_3.1-8 ## [85] abind_1.4-5 modelr_0.1.5 crayon_1.3.4 ## [88] utf8_1.1.4 rmarkdown_2.0 jpeg_0.1-8.1 ## [91] grid_3.6.2 readxl_1.3.1 data.table_1.12.8 ## [94] reprex_0.3.0 digest_0.6.23 webshot_0.5.2 ## [97] xtable_1.8-4 numDeriv_2016.8-1.1 munsell_0.5.0 ## [100] viridisLite_0.3.0 "]
]
