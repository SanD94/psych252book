--- 
title: "Psych 252: Statistical Methods for Behavioral and Social Sciences"
author: "Tobias Gerstenberg"
date: "`r Sys.Date()`"
book_filename: "psych252"
language:
  ui:
    chapter_name: "Chapter "
delete_merged_file: true
output_dir: "docs"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: psych252/psych252book
description: "Course notes for Psych 252."
---

# Preface {-}

Placeholder



<!--chapter:end:index.Rmd-->


# Introduction

Placeholder


## Thanks 
## List of R packages used in this book 

<!--chapter:end:01-introduction.Rmd-->


# Visualization 1

Placeholder


## Learning objectives 
## Load packages
## Why visualize data?
### How _not_ to visualize data
### How to make it better
## Setting up RStudio
## Getting help
## Data visualization using `ggplot2`
### Setting up a plot
### Setting the default plot theme
### Scatter plot
#### Practice plot 1
### Line plot
### Adding error bars
#### Order matters
#### Practice plot 2
### Grouping data
#### Practice plot 3
### Making facets
#### Practice plot 4
### Global, local, and setting `aes()`
## Additional resources
### Cheatsheets
### Data camp courses
### Books and chapters
### Misc

<!--chapter:end:02-visualization1.Rmd-->


# Visualization 2

Placeholder


## Learning objectives 
## Install and load packages, load data, set theme
## Overview of different plot types for different things 
### Proportions 
#### Stacked bar charts 
#### Pie charts 
### Comparisons 
#### Boxplots
#### Violin plots
#### Joy plots
#### Practice plot
### Relationships 
#### Scatter plots
#### Raster plots 
### Temporal data 
## Customizing plots 
### Changing the order of things
### Dealing with legends 
### Choosing good colors
### Customizing themes 
## Saving plots 
## Creating figure panels 
## Peeking behind the scenes 
## Making animations 
## Shiny apps 
## Defining snippets 
## Additional resources 
### Cheatsheets 
### Data camp courses 
### Books and chapters
### Misc

<!--chapter:end:03-visualization2.Rmd-->


# Data wrangling 1 

Placeholder


## Learning objectives 
## Install packages 
## Load packages 
## Some R basics 
### Modes 
### Data types
#### Vectors 
#### Matrix 
#### Array 
#### Data frame 
#### Lists 
### Operators
### Control flow 
#### if-then {#if-else}
#### for loop
#### while loop 
### Functions 
#### Some often used functions 
### The pipe operator `%>%` 
#### Practice 1 
## Looking at data
### `head()`
### `glimpse()`
### `distinct()`
### `count()`
### `datatable()`
### Other tools for taking a quick look at data 
#### `vis_dat()`
#### `skim()`
#### `dfSummary()`
### A quick note on naming things 
## Wrangling data 
### filter() 
### rename() 
### select() 
### mutate() 
#### mutate_at()
#### mutate_all()
#### mutate_if()
### arrange() 
### Practice 2 
## Additional resources 
### Cheatsheets 
### Data camp courses
### Books and chapters

<!--chapter:end:04-data_wrangling1.Rmd-->


# Data wrangling 2 

Placeholder


## Learning objectives 
## Load packages 
## Wrangling data (continued)
### Summarizing data 
#### Practice 1 
### Reshaping data 
#### Practice 2 
### Joining multiple data frames 
#### Practice 3
### Dealing with missing data 
## Reading in data 
### csv
### RData 
## Saving data 
### csv 
### RData 
## Additional resources 
### Cheatsheets 
### Data camp courses 
### Books and chapters
### Tutorials 

<!--chapter:end:05-data_wrangling2.Rmd-->


# Probability and causality

Placeholder


## Load packages 
## Counting 
## Flipping a coin many times 
## Clue guide to probability 
### Conditional probability 
### Law of total probability
## Probability operations 
## Bayesian reasoning example
## Bayesian networks 
### Sprinkler example
## Additional resources 
### Cheatsheets 
### Books and chapters
### Misc 

<!--chapter:end:06-probability.Rmd-->


# Simulation 1 

Placeholder


## Load packages and set plotting theme  
## Working with distributions 
### Plotting distributions 
### Sampling from distributions 
### Cumulative probability distribution
### Inverse cumulative distribution 
### Computing probabilities 
#### Via probability distributions
#### Via sampling 
## Bayesian inference with the normal distribution
## Working with samples
### Understanding `density()`
### The `quantile()` function
## Comparing probability distributions 
## Additional resources 
### Cheatsheets 
### Datacamp 

<!--chapter:end:07-simulation1.Rmd-->


# Simulation 2 

Placeholder


## Load packages and set plotting theme  
## The central limit theorem 
### Population distribution 
### Distribution of a single sample 
### The sampling distribution
#### Bootstrapping a sampling distribution
### Exploring the CLT 
#### Distribution of height 
#### Testing the limits 
## Understanding p-values 
### Permutation test 
## Confidence intervals 
## Additional resources 
### Datacamp 

<!--chapter:end:08-simulation2.Rmd-->


# Modeling data

Placeholder


## Load packages and set plotting theme  
## Things that came up in class 
### Calculating RMSE using `magrittr` verbs
### Relationship between probability and likelihood 
## Modeling data 
### Simplicity vs. accuracy trade-off 
### Error definitions and best estimators
### Sampling distributions for median and mean 
## Hypothesis testing: "One-sample t-test" 
## Additional resources 
### Reading 
### Datacamp 

<!--chapter:end:09-modeling_data.Rmd-->


# Linear model 1

Placeholder


## Load packages and set plotting theme  
## Things that came up in class 
### Building a sampling distribution of PRE 
### Correlation 
#### Variance 
#### Covariance 
#### Spearman's rank order correlation
## Regression 
### Define and fit the models
### Calculate the sum of squared errors of each model
## Credit example
## Additional resources 
### Datacamp 
### Misc 

<!--chapter:end:10-linear_model1.Rmd-->


# Linear model 2

Placeholder


## Load packages and set plotting theme  
## Load data sets 
## Things that came up in class
## Multiple continuous variables 
### Explore correlations 
#### Visualize correlations
##### Correlations with the dependent variable
##### All pairwise correlations
### Multipe regression
#### Visualization
#### Fitting, hypothesis testing, evaluation
#### Visualizing the model fits 
#### Interpreting the model fits
#### Standardizing the predictors
## One categorical variable
### Visualization of the model predictions
### Dummy coding 
### Reporting the results
## One continuous and one categorical variable
### Visualization of the model predictions
## Interactions
### Visualization
### Hypothesis test 
## Additional resources 
### Datacamp 
### Misc 

<!--chapter:end:11-linear_model2.Rmd-->


# Linear model 3

Placeholder


## Load packages and set plotting theme  
## Load data sets 
### One-way ANOVA
#### Visualization 
#### Model fitting 
#### Hypothesis test 
#### Visualize the model's predictions 
#### Dummy coding
#### Follow up questions
## Two-way ANOVA 
### Visualization
### Model fitting
### Interpreting interactions 
## Additional resources 
### Datacamp 
### Misc 

<!--chapter:end:12-linear_model3.Rmd-->


# Linear model 4

Placeholder


## Load packages and set plotting theme  
## Load data sets
## Variance decomposition in one-way ANOVA
### Calculate sums of squares
### Visualize model predictions 
#### Total variance
#### Model variance
#### Residual variance 
## Two-way ANOVA (linear model)
### Calculate sums of squares
### Visualize model predictions
#### `Skill` factor
## ANOVA with unbalanced design
## Two-way ANOVA (with interaction)
## Planned contrasts 
### Hypothetical data 
### Visualization
### Constrasts 
### Post-hoc tests

<!--chapter:end:13-linear_model4.Rmd-->


# Power analysis

Placeholder


## Load packages and set plotting theme  
## Load data sets 
## Decision-making 
## Effect sizes
### eta-squared and partial eta-squared
### Cohen's d
## Determining sample size 
### `pwr` package
### Simulation
## Additional resources 

<!--chapter:end:14-power_analysis.Rmd-->

# Bootstrapping

This chapter was written by Andrew Lampinen. 

```{r bootstrapping-01, include=FALSE, eval=FALSE}
devtools::install_github("thomasp85/patchwork", force=T)
```

## Load packages and set plotting theme  

```{r bootstrapping-02, message=FALSE}
library("knitr")     # for knitting RMarkdown 
library("boot")      # for bootstrapping
library("patchwork") # for making figure panels
library("tidyverse") # for data wrangling etc.

opts_chunk$set(
  comment = "",
  results = "hold",
  fig.show = "hold"
)
```

```{r bootstrapping-03}
theme_set(
  theme_classic() #set the theme 
)
```

## What's wrong with parametric tests?

### T-tests on non-normal distributions

Let's see some examples! One common non-normal distribution is the *log-normal* distribution, i.e. a distribution that is normal after you take its logarithm. Many natural processes have distributions like this. One of particular interest to us is reaction times.

```{r bootstrapping-04}
num_points = 1e4
parametric_plotting_data = tibble(
  distribution = rep(c("Normal", "Log-normal"), each = num_points),
  value = c(
    rnorm(num_points, 0, 1), # normal
    exp(rnorm(num_points, 0, 1)) - exp(1 / 2)
  )
) %>%
  mutate(distribution = factor(distribution, levels = c("Normal", "Log-normal")))
```

Let's see how violating the assumption of normality changes the results of `t.test`. We'll compare two situations 

Valid: comparing two normally distributed populations with equal means but unequal variances.

Invalid: comparing two log-normally distributed populations with equal means but unequal variances.

```{r bootstrapping-05}
ggplot(parametric_plotting_data, aes(x = value, color = distribution)) +
  geom_density(bw = 0.5, size = 1) +
  geom_vline(
    data = parametric_plotting_data %>%
      group_by(distribution) %>%
      summarize(mean_value = mean(value), sd_value = sd(value)),
    aes(xintercept = mean_value, color = distribution),
    linetype = 2, size = 1
  ) +
  xlim(-5, 20) +
  facet_grid(~distribution, scales = "free") +
  guides(color = F) +
  scale_color_brewer(palette = "Accent")
```

```{r bootstrapping-06}
ggsave("figures/log_normal_dists.png", width=5, height=3)
```

```{r bootstrapping-07}
gen_data_and_test = function(num_observations_per) {
  x = rnorm(num_observations_per, 0, 1.1)
  y = rnorm(num_observations_per, 0, 1.1)

  pnormal = t.test(x, y, var.equal = T)$p.value

  # what if the data are log-normally distributed?
  x = exp(rnorm(num_observations_per, 0, 1.1))
  y = exp(rnorm(num_observations_per, 0, 1.1))

  pnotnormal = t.test(x, y, var.equal = T)$p.value
  return(c(pnormal, pnotnormal))
}

parametric_issues_demo = function(num_tests, num_observations_per) {
  replicate(num_tests, gen_data_and_test(num_observations_per))
}
```

```{r bootstrapping-08}
set.seed(0) # ensures we get the same results each time we run it

num_tests = 1000 # how many datasets to generate/tests to run
num_observations_per = 20 # how many obsservations in each dataset

parametric_issues_results = parametric_issues_demo(num_tests=num_tests, 
                                                   num_observations_per=num_observations_per)

parametric_issues_d = data.frame(valid_tests = parametric_issues_results[1,],
                                 invalid_tests = parametric_issues_results[2,],
                                 iteration=1:num_tests) %>%
  gather(type, p_value, contains("tests")) %>%
  mutate(is_significant = p_value < 0.05)

# Number significant results with normally distributed data
sum(parametric_issues_results[1,] < 0.05)

# number of significant results with log-normally distributed data
sum(parametric_issues_results[2,] < 0.05)
```
 
```{r bootstrapping-09}
ggplot(parametric_issues_d, aes(x=type, fill=is_significant)) +
  geom_bar(stat="count", color="black") +
  scale_fill_brewer(palette="Set1") +
  labs(title="Parametric t-test")
```

That's a non-trivial reduction in power from a misspecified model! (~80% to ~54%).

```{r bootstrapping-10, cache=TRUE}
boot_mean_diff_test = function(x, y) {
  obs_t = t.test(x, y)$statistic
  boot_iterate = function(x, y, indices) { # indices is a dummy here
    x_samp = sample(x, 
                    length(x), 
                    replace=T)
    y_samp = sample(y, 
                    length(y), 
                    replace=T)
    mean_diff = mean(y_samp) - mean(x_samp)
    return(mean_diff)
  }
  boots = boot(data = c(x, y), boot_iterate, R=500)
  #  boots = replicate(100, boot_iterate(x, y))
  #  quants = quantile(boots, probs=c(0.025, 0.975))
  quants = boot.ci(boots)$bca[4:5]
  return(sign(quants[1]) == sign(quants[2]))
}
```

(Omitted because with these small sample sizes bootstrapping is problematic -- permutations are better)

```{r bootstrapping-11}
# gen_data_and_boot_test = function(num_observations_per) {
# x = rnorm(num_observations_per, 0, 1.1)
# y = rnorm(num_observations_per, 0, 1.1)
# 
# pnormal = boot_mean_diff_test(x, y)
# 
# # what if the data are log-normally distributed?
# x = exp(rnorm(num_observations_per, 0, 1.1))
# y = exp(rnorm(num_observations_per, 1, 1.1))
# 
# pnotnormal = boot_mean_diff_test(x, y)
# return(c(pnormal, pnotnormal))
# }
# 
# boot_results = replicate(num_tests, gen_data_and_boot_test(num_observations_per))
# sum(boot_results[1,])
# sum(boot_results[2,])
```

While the bootstrap **actually loses power** relative to a perfectly specified model, it is much more **robust** to changes in the assumptions of that model, and so it **retains more power when assumptions are violated**.
 

```{r bootstrapping-12}
perm_mean_diff_test = function(x, y) {
  obs_t = t.test(x, y)$statistic
  combined_data = c(x, y)
  n_combined = length(combined_data)
  n_x = length(x)
  perm_iterate = function(x, y) {
    perm = sample(n_combined)
    x_samp = combined_data[perm[1:n_x]]
    y_samp = combined_data[perm[-(1:n_x)]]
    this_t = t.test(x_samp, y_samp)$statistic
    return(this_t)
  }
  perms = replicate(500, perm_iterate(x, y))
  quants = quantile(perms, probs=c(0.025, 0.975))
  return(obs_t < quants[1] | obs_t > quants[2])
}
```

```{r bootstrapping-13, message=F, warning=FALSE, cache=TRUE}
# this could be much more efficient
gen_data_and_norm_and_perm_test = function(num_observations_per) {
  d = data.frame(distribution=c(),
                 null_true=c(),
                 parametric=c(),
                 permutation=c()) 
    
  # normally distributed 
  ## null
  x = rnorm(num_observations_per, 0, 1.1)
  y = rnorm(num_observations_per, 0, 1.1)
  
  sig_par = t.test(x, y)$p.value < 0.05
  sig_perm = perm_mean_diff_test(x, y)
  d = bind_rows(d, 
                data.frame(distribution="Normal",
                           null_true=T,
                           parametric=sig_par,
                           permutation=sig_perm))
  
  ## non-null
  x = rnorm(num_observations_per, 0, 1.1)
  y = rnorm(num_observations_per, 1, 1.1)
  
  sig_par = t.test(x, y)$p.value < 0.05
  sig_perm = perm_mean_diff_test(x, y)
  d = bind_rows(d, 
                data.frame(distribution="Normal",
                           null_true=F,
                           parametric=sig_par,
                           permutation=sig_perm))
  
  # what if the data are log-normally distributed?
  ## null
  x = exp(rnorm(num_observations_per, 0, 1.1))
  y = exp(rnorm(num_observations_per, 0, 1.1))
  
  sig_par = t.test(x, y)$p.value < 0.05
  sig_perm = perm_mean_diff_test(x, y)
  d = bind_rows(d, 
                data.frame(distribution="Log-normal",
                           null_true=T,
                           parametric=sig_par,
                           permutation=sig_perm))
  
  ## non-null
  x = exp(rnorm(num_observations_per, 0, 1.1))
  y = exp(rnorm(num_observations_per, 1, 1.1))
  
  sig_par = t.test(x, y)$p.value < 0.05
  sig_perm = perm_mean_diff_test(x, y)
  d = bind_rows(d, 
                data.frame(distribution="Log-normal",
                           null_true=F,
                           parametric=sig_par,
                           permutation=sig_perm))
  
  return(d)
}
num_tests = 100

perm_results = replicate(num_tests, gen_data_and_norm_and_perm_test(num_observations_per),
                         simplify=F) %>%
  bind_rows()
```

```{r bootstrapping-14}
perm_results = perm_results %>%
  gather(test_type, significant, parametric, permutation) %>%
  mutate(distribution=factor(distribution, levels=c("Normal", "Log-normal")),
         null_true=ifelse(null_true, 
                          "Null True",
                          "Alternative True"))
```

```{r bootstrapping-15}
ggplot(perm_results %>%
  filter(null_true == "Alternative True"), aes(x = test_type, fill = significant)) +
  geom_bar(stat = "count", color = "black") +
  scale_fill_brewer(palette = "Set1") +
  facet_grid(null_true ~ distribution) +
  geom_hline(
    data = data.frame(
      null_true = "Alternative True",
      alpha = num_tests * 0.8
    ),
    mapping = aes(yintercept = alpha),
    linetype = 2,
    size = 1,
    alpha = 0.5
  ) +
  labs(x = "Test type", y = "Percent") +
  scale_y_continuous(
    breaks = c(0, 0.8, 1) * num_tests,
    labels = paste(c(0, 80, 100), "%", sep = "")
  )
```

```{r bootstrapping-16}
ggsave("figures/perm_test.png", width=5, height=3)
```

```{r bootstrapping-17}
perm_results %>% 
  group_by(test_type, distribution, null_true) %>%
  summarize(pct_significant = sum(significant)/n())
```

### Non-IID noise and linear models

```{r bootstrapping-18}
num_points = 500
true_intercept = 0
true_slope = 1.
set.seed(0)
parametric_ci_data = data.frame(IV = rep(runif(num_points,  -1, 1), 2),
                                type = rep(c("IID Error", "Non-IID Error"), each=num_points),
                                error = rep(rnorm(num_points, 0, 1), 2)) %>%
  mutate(DV = ifelse(
    type == "IID Error",
    true_slope*IV + error,
    true_slope*IV + 2*abs(IV)*error)) # error increases proportional to distance from 0 on the IV

```

```{r bootstrapping-19}
ggplot(
  parametric_ci_data,
  aes(x = IV, y = DV, color = type)
) +
  geom_point(alpha = 0.5) +
  geom_smooth(
    method = "lm", se = T, color = "black",
    size = 1.5, level = 0.9999
  ) + # inflating the confidence bands a bit
  # to show their distribution is similar
  scale_color_brewer(palette = "Accent") +
  facet_wrap(~type) +
  guides(color = F)
```

```{r bootstrapping-20}
ggsave("figures/error_dist_non_null.png", width=5, height=3)
```

C.f. Anscombe's quartet, etc.

```{r bootstrapping-21}
summary(lm(DV ~ IV, parametric_ci_data %>% filter(type=="IID Error")))
summary(lm(DV ~ IV, parametric_ci_data %>% filter(type=="Non-IID Error")))
```

```{r bootstrapping-22}
ex2_lm_bootstrap_CIs = function(data, R = 1000) {
  lm_results = summary(lm(DV ~ IV, data = data))$coefficients
  bootstrap_coefficients = function(data, indices) {
    linear_model = lm(DV ~ IV,
      data = data[indices, ]
    ) # will select a bootstrap sample of the data
    return(linear_model$coefficients)
  }

  boot_results = boot(
    data = data,
    statistic = bootstrap_coefficients,
    R = R
  )
  boot_intercept_CI = boot.ci(boot_results, index = 1, type = "bca")
  boot_slope_CI = boot.ci(boot_results, index = 2, type = "bca")
  return(data.frame(
    intercept_estimate = lm_results[1, 1],
    intercept_SE = lm_results[1, 2],
    slope_estimate = lm_results[2, 1],
    slope_SE = lm_results[2, 2],
    intercept_boot_CI_low = boot_intercept_CI$bca[4],
    intercept_boot_CI_hi = boot_intercept_CI$bca[5],
    slope_boot_CI_low = boot_slope_CI$bca[4],
    slope_boot_CI_hi = boot_slope_CI$bca[5]
  ))
}
```

```{r bootstrapping-23}
set.seed(0) # for bootstraps
coefficient_CI_data = parametric_ci_data %>%
  group_by(type) %>%
  do(ex2_lm_bootstrap_CIs(.)) %>%
  ungroup() 
```

```{r bootstrapping-24}
coefficient_CI_data = coefficient_CI_data %>%
  gather(variable, value, -type) %>%
  separate(variable, c("parameter", "measurement"), extra = "merge") %>%
  spread(measurement, value) %>%
  mutate(
    parametric_CI_low = estimate - 1.96 * SE,
    parametric_CI_hi = estimate + 1.96 * SE
  ) %>%
  gather(CI_type, value, contains("CI")) %>%
  separate(CI_type, c("CI_type", "high_or_low"), extra = "merge") %>%
  spread(high_or_low, value) %>%
  mutate(CI_type = factor(CI_type))
```

```{r bootstrapping-25}
plot_coefficient_CI_data = function(coefficient_CI_data, errorbar_width = 0.5) {
  p = ggplot(data = coefficient_CI_data, aes(x = parameter, color = CI_type, y = estimate, ymin = CI_low, ymax = CI_hi)) +
    geom_hline(
      data = data.frame(
        parameter = c("intercept", "slope"),
        estimate = c(true_intercept, true_slope)
      ),
      mapping = aes(yintercept = estimate),
      linetype = 3
    ) +
    geom_point(size = 2, position = position_dodge(width = 0.2)) +
    geom_errorbar(position = position_dodge(width = 0.2), width = errorbar_width) +
    facet_grid(~type) +
    scale_y_continuous(breaks = c(0, 0.5, 1), limits = c(-0.2, 1.5)) +
    scale_color_brewer(palette = "Dark2", drop = F)
}
```

```{r bootstrapping-26}
plot_coefficient_CI_data(coefficient_CI_data)
ggsave("figures/error_dist_CI_example.png", width = 5, height = 3)

plot_coefficient_CI_data(
  coefficient_CI_data %>%
    filter(CI_type == "parametric"), 0.25)

ggsave("figures/error_dist_CI_example_parametric_only.png", width = 5, height = 3)
```

Challenge Q: Why isn't the error on the intercept changed in the scaling error case?

This can result in CIs which aren't actually at the nominal confidence level! And since CIs are equivalent to t-tests in this setting, this can also increase false positive rates.
(Also equivalent to Bayesian CrIs.)


```{r bootstrapping-27}
num_points = 200
true_intercept = 0
true_slope = 0.
set.seed(0)
parametric_ci_data = data.frame(IV = rep(runif(num_points,  -1, 1), 2),
                                type = rep(c("IID Error", "Non-IID Error"), each=num_points),
                                error = rep(rnorm(num_points, 0, 1), 2)) %>%
  mutate(DV = ifelse(
    type == "IID Error",
    true_slope*IV + error,
    true_slope*IV + 2*abs(IV)*error)) # error increases proportional to distance from 0 on the IV

```

```{r bootstrapping-28}
ggplot(
  parametric_ci_data,
  aes(x = IV, y = DV, color = type)
) +
  geom_point(alpha = 0.5) +
  geom_smooth(
    method = "lm", se = T, color = "black",
    size = 1.5, level = 0.9999
  ) + # inflating the confidence bands a bit
  # to show their distribution is similar
  scale_color_brewer(palette = "Accent") +
  facet_wrap(~type) +
  guides(color = F)
```

```{r bootstrapping-29}
ggsave("figures/error_dist_null.png", width=5, height=3)
```

```{r bootstrapping-30, cache=TRUE}

error_dist_null_sample = function(num_points) {
  true_intercept = 0
  true_slope = 0
  # We'll sample only for the scaling error case, we know IID works
  this_data = data.frame(IV = runif(num_points, -1, 1),
                         error = rnorm(num_points, 0, 1)) %>%
    mutate(DV = true_slope * IV + 2 * abs(IV) * error) # error increases proportional to distance from 0 on the IV
  
  coefficient_CI_data = ex2_lm_bootstrap_CIs(this_data,
                                             R = 200) # take fewer bootstrap samples, to speed things up
  
  coefficient_CI_data = coefficient_CI_data %>%
    gather(variable, value) %>%
    separate(variable, c("parameter", "measurement"), extra = "merge") %>%
    spread(measurement, value) %>%
    mutate(parametric_CI_low = estimate - 1.96 * SE,
           parametric_CI_hi = estimate + 1.96 * SE) %>%
    gather(CI_type, value, contains("CI")) %>%
    separate(CI_type, c("CI_type", "high_or_low"), extra = "merge") %>%
    spread(high_or_low, value) %>%
    mutate(significant = sign(CI_hi) == sign(CI_low)) %>%
    select(parameter, CI_type, significant)
  return(list(coefficient_CI_data))
}
```

```{r bootstrapping-31, cache=TRUE}
num_simulations = 100
num_points = 200
set.seed(0)
noise_dist_simulation_results = replicate(num_simulations, error_dist_null_sample(num_points)) %>%
  bind_rows()
```

```{r bootstrapping-32}
ggplot(noise_dist_simulation_results, aes(x = CI_type, fill = significant)) +
  geom_bar(stat = "count", color = "black") +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  facet_wrap(~parameter) +
  scale_y_continuous(breaks = c(0, 0.05 * num_simulations, num_simulations),
                     labels = c("0%", expression(Nominal ~ alpha), "100%")) +
  labs(x = "Test type",
       y = "Proportion significant") +
  geom_hline(yintercept = 0.05 * num_simulations, linetype = 2)
```

```{r bootstrapping-33}
ggsave("figures/error_dist_proportion_significant.png", width=5, height=3)
```

```{r bootstrapping-34}
noise_dist_simulation_results %>%
  count(parameter, CI_type, significant) %>%
  mutate(prop=n/num_simulations)
```

False positive rate nearly triples for the parametric model!

### Density estimate conceptual plot

```{r bootstrapping-35}
density_similarity_conceptual_plot_data = expand.grid(
  x = seq(0, 4, 0.01),
  y = seq(0, 4, 0.01)
) %>%
  mutate(
    population_1 = exp(-((x - 2)^2 + (y - 3)^2) / 8) * exp(-((x - 2 / y)^2 + (y - 1 / x)^2) / 2), # These are definitely not proper distributions
    population_2 = exp(-((x)^2 + (y)^2) / 8) * exp(-((x / 2)^2 + (y / 2 - 1 / x)^2) / 2)
  ) %>%
  gather(population, value, contains("population"))
```

```{r bootstrapping-36}
ggplot(
  density_similarity_conceptual_plot_data,
  aes(x = x, y = y, z = value, color = population)
) +
  geom_contour(size = 1, bins = 8) +
  scale_color_brewer(palette = "Dark2") +
  facet_wrap(~population) +
  labs(x = "Feature 1", y = "Feature 2") +
  guides(color = F)
```

```{r bootstrapping-37}
ggsave("figures/conceptual_density_plot.png", width=5, height=3)
```

## Bootstrap resampling

### Demo
```{r bootstrapping-38}
num_points = 100
true_intercept = 0
true_slope = 1.
set.seed(2) # I p-hacked the shit out of this demo to make the ideas more clear
parametric_ci_data = data.frame(
  IV = rep(runif(num_points, -1, 1), 2),
  type = rep(c("IID Error", "Scaling Error"), each = num_points),
  error = rep(rnorm(num_points, 0, 1), 2)
) %>%
  mutate(DV = ifelse(
    type == "IID Error",
    true_slope * IV + error,
    true_slope * IV + 2 * abs(IV) * error
  )) # error increases proportional to distance from 0 on the IV
```

```{r bootstrapping-39}
p = ggplot(parametric_ci_data,
           aes(x = IV, y = DV)) +
  geom_point(alpha = 0.25) +
  geom_smooth(method = "lm", se = F, color = "black",
              size = 1.5) +
  facet_wrap(~type)
p
```

```{r bootstrapping-40}
ggsave("figures/bootstrap_demo_0.png", width=5, height=3)
```

```{r bootstrapping-41}
set.seed(15) # See above RE: p-hacking
samp_1_indices = sample(2:num_points, num_points, replace = T)
samp_1 = parametric_ci_data[c(samp_1_indices, samp_1_indices + num_points), ] # take the same rows from each type of data

set.seed(2) # See above RE: p-hacking
samp_2_indices = sample(1:num_points, num_points, replace = T)
samp_2 = parametric_ci_data[c(samp_2_indices, samp_2_indices + num_points), ]

many_samples_indices = sample(1:num_points, 8 * num_points, replace = T)
many_samples = bind_rows(
  samp_1 %>%
    mutate(sample = 1),
  samp_2 %>% mutate(sample = 2),
  parametric_ci_data[c(many_samples_indices, many_samples_indices + num_points), ] %>%
    mutate(sample = rep(rep(3:10, each = num_points), 2))
)
```

```{r bootstrapping-42}
p +
  geom_point(
    data = samp_1,
    aes(color = NA), color = "red", alpha = 0.5
  )

```

```{r bootstrapping-43}
ggsave("figures/bootstrap_demo_1.png", width=5, height=3)
```

```{r bootstrapping-44}
p +
  geom_point(
    data = samp_1,
    aes(color = NA), color = "red", alpha = 0.5
  ) +
  geom_smooth(
    data = samp_1,
    method = "lm", se = F, color = "red",
    size = 1.5
  )

```

```{r bootstrapping-45}
ggsave("figures/bootstrap_demo_2.png", width=5, height=3)
```

```{r bootstrapping-46}
p + 
  geom_point(data=samp_2,
             aes(color=NA), color="red", alpha=0.5) 
```

```{r bootstrapping-47}
ggsave("figures/bootstrap_demo_3.png", width=5, height=3)
```


```{r bootstrapping-48}
p +
  geom_point(
    data = samp_2,
    aes(color = NA), color = "red", alpha = 0.5
  ) +
  geom_smooth(
    data = samp_2,
    method = "lm", se = F, color = "red",
    size = 1.5
  )
```

```{r bootstrapping-49}
ggsave("figures/bootstrap_demo_4.png", width=5, height=3)
```

```{r bootstrapping-50}
p +
  geom_smooth(
    data = many_samples,
    aes(group = sample),
    method = "lm", se = F,
    size = 1.5,
    color = "red"
  )
```

```{r bootstrapping-51}
ggsave("figures/bootstrap_demo_5.png", width=5, height=3)
```

## Applications

### Bootstrap confidence intervals

```{r bootstrapping-52}
num_top_points = 23
num_mid_points = 4
num_outlier_points = 2
max_score = 100
set.seed(0)
test_score_data = data.frame(
  score = c(rbinom(num_top_points, max_score, 0.9999),
            rbinom(num_mid_points, max_score, 0.97),
            sample(0:max_score, num_outlier_points, replace = T)),
  type = "Observed sample"
)
```

```{r bootstrapping-53, cache=TRUE}
get_mean_score = function(data, indices) {
  return(mean(data[indices,]$score))
}

bootstrap_results = boot(test_score_data, get_mean_score, R=100)
bootstrap_CIs = boot.ci(bootstrap_results)
bootstrap_CIs
```

```{r bootstrapping-54}
test_summary_data = test_score_data %>%
  summarise(
    mean = mean(score),
    se = sd(score) / sqrt(n()),
    parametric_CI_low = mean - 1.96 * se,
    parametric_CI_high = mean + 1.96 * se
  )

test_score_data = test_score_data %>%
  bind_rows(
    data.frame(score = bootstrap_results$t, type = "Boot. sampling dist.")
  ) %>%
  mutate(type = factor(type, levels = c("Observed sample", "Boot. sampling dist.")))

test_summary_data = test_summary_data %>%
  mutate(
    type = factor("Boot. sampling dist.", levels = levels(test_score_data$type)),
    percentile_CI_low = bootstrap_CIs$percent[4],
    percentile_CI_high = bootstrap_CIs$percent[5],
    bca_CI_low = bootstrap_CIs$bca[4],
    bca_CI_high = bootstrap_CIs$bca[5]
  ) %>%
  gather(CI_type, value, contains("CI")) %>%
  separate(CI_type, c("CI_type", "endpoint"), extra = "merge") %>%
  spread(endpoint, value) %>%
  mutate(
    y = c(170, 210, 190),
    CI_type = factor(CI_type, levels = c("parametric", "percentile", "bca"), labels = c("Normal", "Boot: %", "Boot: BCA"))
  )
```

```{r bootstrapping-55}
ggplot(test_summary_data %>%
  filter(CI_type != "Boot: BCA"), aes(x = score)) +
  geom_histogram(
    data = test_score_data,
    binwidth = 1
  ) +
  geom_point(
    mapping = aes(x = mean, y = y, color = CI_type),
    size = 2
  ) +
  geom_errorbarh(
    mapping = aes(y = y, color = CI_type, xmin = CI_low, x = NULL, xmax = CI_high),
    size = 1,
    position = position_dodge()
  ) +
  facet_grid(type ~ ., scales = "free_y") +
  scale_color_brewer(palette = "Dark2") +
  guides(color = guide_legend(title = "CI"))
```

```{r bootstrapping-56}
ggsave("figures/bootstrap_CI_0.png", width=5, height=3)
```

```{r bootstrapping-57}
ggplot(test_summary_data, aes(x = score)) +
  geom_histogram(
    data = test_score_data,
    binwidth = 1
  ) +
  geom_point(
    mapping = aes(x = mean, y = y, color = CI_type),
    size = 2
  ) +
  geom_errorbarh(
    mapping = aes(y = y, color = CI_type, xmin = CI_low, x = NULL, xmax = CI_high),
    size = 1,
    position = position_dodge()
  ) +
  facet_grid(type ~ ., scales = "free_y") +
  scale_color_brewer(palette = "Dark2") +
  guides(color = guide_legend(title = "CI"))
ggsave("figures/bootstrap_CI_1.png", width = 5, height = 3)
```

### Bootstrap (& permutation) hypothesis tests

```{r bootstrapping-58}
num_flips = 20
true_heads_prob = 0.9
set.seed(2)
flips = rbinom(num_flips, 1, true_heads_prob)
flip_data = data.frame(flip_result = factor(flips, labels = c("Tails", "Heads")))
```

```{r bootstrapping-59}
flip_data_plot = ggplot(data = flip_data, aes(x = flips, fill = flips)) +
  geom_dotplot(binwidth = 0.03) +
  scale_x_continuous(
    breaks = c(0, 1),
    labels = c("tails", "heads")
  ) +
  scale_y_continuous(breaks = c()) +
  labs(x = "Flip result", y = "")
```

```{r bootstrapping-60}
get_mean_heads = function(data, indices) {
  return(mean(data[indices, "flip_result"] == "Heads"))
}

set.seed(0)
bootstrap_results = boot(flip_data, get_mean_heads, R = 20000)
bootstrap_CIs = boot.ci(bootstrap_results)
bootstrap_CIs
```

```{r bootstrapping-61}
flip_boot_plot = ggplot(
  data = data.frame(mean_flips = bootstrap_results$t),
  aes(x = mean_flips)
) +
  geom_histogram(binwidth = 0.05) +
  xlim(0, 1) +
  geom_vline(
    xintercept = 0.5,
    color = "red",
    size = 1.1
  ) +
  annotate("text",
    label = "Null value",
    color = "red",
    x = 0.43, y = 2500,
    angle = 90,
    size = 4
  ) +
  annotate("text",
    label = "95% CI",
    color = "blue",
    x = 0.75, y = 5400,
    size = 4
  ) +
  geom_errorbarh(aes(
    xmin = bootstrap_CIs$bca[4],
    xmax = bootstrap_CIs$bca[5],
    y = 5100
  ),
  color = "blue",
  size = 1.1,
  height = 200
  ) +
  labs(x = "Boot. sampling dist.")

flip_boot_plot
```

```{r bootstrapping-62}
flip_data_plot + 
  flip_boot_plot +
  plot_layout()

ggsave("figures/bootstrap_test.png", width = 5, height = 2.5)
```

```{r bootstrapping-63}
bootstrap_CIs = boot.ci(bootstrap_results, conf = 0.999)

flip_boot_plot = ggplot(
  data = data.frame(mean_flips = bootstrap_results$t),
  aes(x = mean_flips)
) +
  geom_histogram(binwidth = 0.05) +
  xlim(0, 1) +
  geom_vline(
    xintercept = 0.5,
    color = "red",
    size = 1.1
  ) +
  annotate("text",
    label = "Null value",
    color = "red",
    x = 0.43, y = 2500,
    angle = 90,
    size = 4
  ) +
  annotate("text",
    label = "99.9% CI",
    color = "blue",
    x = 0.75, y = 5400,
    size = 4
  ) +
  geom_errorbarh(aes(
    xmin = bootstrap_CIs$bca[4],
    xmax = bootstrap_CIs$bca[5],
    y = 5100
  ),
  color = "blue",
  size = 1.1,
  height = 200
  ) +
  labs(x = "Boot. sampling dist.")

flip_boot_plot
```

```{r bootstrapping-64}
flip_data_plot + flip_boot_plot +
  plot_layout()

ggsave("figures/bootstrap_test_999.png", width=5, height=2.5)
```

<!--chapter:end:15-bootstrapping.Rmd-->


# Model comparison

Placeholder


## Load packages and set plotting theme  
## Determining sample size 
### `pwr` package
### `map()`
### via simulation
#### simple example 
#### more advanced example
## Model comparison 
### Fitting vs. predicting
### F-test 
### Cross-validation 
#### Leave-one-out cross-validation 
#### k-fold cross-validation 
#### Monte Carlo cross-validation 
### Bootstrap 
### AIC and BIC 
#### log() is your friend 
## Additional resources 
### Cheatsheet 
### Datacamp course
### Reading 
### Misc 

<!--chapter:end:16-model_comparison.Rmd-->


# Linear mixed effects models 1

Placeholder


## Load packages and set plotting theme  
## Things that came up in class 
### Comparing t-test with F-test in `lm()`
#### Global F-test 
#### Test for individual predictors
## Dependence 
## Additional resources 
### Readings 

<!--chapter:end:17-linear_mixed_effects_models1.Rmd-->


# Linear mixed effects models 2

Placeholder


## Load packages and set plotting theme  
## Things that came up in class 
### Difference between `replicate()` and `map()`
## Simulating a linear mixed effects model 
## The effect of outliers 
## Different slopes 
## Simpson's paradox 
## Additional resources 
### Readings 

<!--chapter:end:18-linear_mixed_effects_models2.Rmd-->


# Linear mixed effects models 3

Placeholder


## Load packages and set plotting theme  
## Load data set 
## Things that came up in class 
### One-tailed vs. two-tailed tests
#### t distribution
#### F distribution
### Mixtures of participants 
#### Ignoring mixture
#### Modeling mixture
#### Heterogeneity in variance
## Pooling and shrinkage 
### Complete pooling 
### No pooling 
### Partial pooling 
#### Random intercept and random slope
#### Only random intercepts 
#### Only random slopes 
### Compare results 
### Coefficients 
### Shrinkage 
## Bootstrapping 
### Linear model 
#### bootmer() function
## Getting p-values 
## Understanding the lmer() syntax 

<!--chapter:end:19-linear_mixed_effects_models3.Rmd-->


# Generalized linear model 

Placeholder


## Load packages and set plotting theme  
## Load data set 
## Logistic regression 
### Interpreting the parameters 
#### Binary predictor
#### Continuous predictor
#### Several predictors 
#### Using the "effects" package 
## Simulate a logistic regression
#### Calculate the model's likelihood 
## Testing hypotheses
## Logistic mixed effects model 
## Additional information 
### Datacamp 

<!--chapter:end:20-generalized_linear_model.Rmd-->


# Bayesian data analysis 1

Placeholder


## Load packages and set plotting theme  
## Things that came up 
### Bias in Cosyne 2019 conference admission? 

<!--chapter:end:21-bayesian_data_analysis1.Rmd-->


# Bayesian data analysis 2

Placeholder


## Load packages and set plotting theme  
## Doing Bayesian inference "by hand"
### Sequential updating based on the Beta distribution 
### Coin flip example 
### Bayesian inference by discretization
### Effect of the prior 
### Effect of the likelihood 
### Effect of the sample size  
## Distributions 
### Normal vs Student-t distribution
### Beta distributions
### Normal distributions 
### Distributions for non-negative parameters 
## Inference via sampling 
## Greta 
### Attitude data set 
### Frequentist analysis 
### Bayesian regression
#### Fit the model
#### Visualize the priors
#### Visualize the posteriors
#### Visualize model predictions 
#### Posterior predictive check 
#### Prior predictive check 

<!--chapter:end:22-bayesian_data_analysis2.Rmd-->


# Bayesian data analysis 3

Placeholder


## Load packages and set plotting theme  
## Load data set 
## Poker 
### Visualization
### Linear model 
### Bayesian model 
#### Visualize the posteriors 
#### Compute highest density intervals 
#### Posterior predictive check 
#### Test hypothesis
#### Bayes factor 
#### Full specification
##### Getting the priors
#### Inference diagnostics
##### When things go wrong 
## Dealing with heteroscedasticity 
## Ordinal regression 
## Additional resources 

<!--chapter:end:23-bayesian_data_analysis3.Rmd-->


# Mediation & Moderation

Placeholder


## Recommended reading 
## Load packages and set plotting theme  
## Mediation 
### Generate data 
### Method 1: Baron & Kenny’s (1986) indirect effect method
#### Total effect 
#### Path a 
#### Path b and c'
#### Interpretation
### Method 2: Sobel Test 
### Method 3: Bootstrapping
#### Interpretation 
### Method 4: Bayesian approach 
## Moderation 
### Generate data 
### Moderation analysis 
#### Visualize result 
## Additional resources 
### Books 
### Tutorials

<!--chapter:end:24-mediation_moderation.Rmd-->


# Cheatsheets

Placeholder


## Statistics 
## R 

<!--chapter:end:25-cheatsheets.Rmd-->

`r if (knitr::is_html_output()) '# References {-}'`

<!--chapter:end:26-references.Rmd-->

